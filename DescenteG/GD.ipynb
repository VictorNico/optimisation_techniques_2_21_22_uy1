{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9cac3117-4197-4149-bb3c-a3fb12ba4e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2ebd361-b264-415f-a379-08c1949b6333",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(gradient, start, learn_rate, n_iter):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        vector += diff\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d093d603-736e-4115-833b-3d614657d42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    gradient, start, learn_rate, n_iter=50, tolerance=1e-06\n",
    "):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * gradient(vector)\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c25a503e-b0f2-44ad-bdff-79bbcd5f24ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.210739197207331e-06"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5d4ee054-57f9-42fd-9ef5-67c97a3cc9fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-4.77519666596786e-07"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8d5c6566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.050060671375367"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d36d5d99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.660323412732294"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.005,n_iter=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a70f6fe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0004317124741065828"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.005,n_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e6440383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9.952518849647663e-05"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 2 * v, start=10.0, learn_rate=0.005,n_iter=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a27c8eef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1.4207567437458342"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 4 * v**3 - 10 * v - 3, start=0,learn_rate=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "60ca8f90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.285401330315467"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 4 * v**3 - 10 * v - 3, start=0,learn_rate=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0a5baa06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000011077232125"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: 1 - 1 / v, start=2.5, learn_rate=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "64f94681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.08281277e-12, 9.75207120e-02])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(gradient=lambda v: np.array([2 * v[0], 4 * v[1]**3]),start=np.array([1.0, 1.0]), learn_rate=0.2, tolerance=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0638aa3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ssr_gradient(x, y, b):\n",
    "    res = b[0] + b[1] * x - y\n",
    "    return res.mean(), (res * x).mean()  # .mean() is a method of np.ndarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f388543e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    gradient, x, y, start, learn_rate=0.1, n_iter=50, tolerance=1e-06\n",
    "):\n",
    "    vector = start\n",
    "    for _ in range(n_iter):\n",
    "        diff = -learn_rate * np.array(gradient(x, y, vector))\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "        vector += diff\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4b40cf50",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([5, 15, 25, 35, 45, 55])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e189c074",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.array([5, 20, 14, 32, 22, 38])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "02f57699",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.62822349, 0.54012867])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_descent(ssr_gradient, x, y, start=[0.5, 0.5], learn_rate=0.0008,n_iter=100_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "096b83d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(\n",
    "    gradient, x, y, start, learn_rate=0.1, n_iter=50, tolerance=1e-06,\n",
    "    dtype=\"float64\"\n",
    "):\n",
    "    # Checking if the gradient is callable\n",
    "    if not callable(gradient):\n",
    "        raise TypeError(\"'gradient' must be callable\")\n",
    "\n",
    "    # Setting up the data type for NumPy arrays\n",
    "    dtype_ = np.dtype(dtype)\n",
    "\n",
    "    # Converting x and y to NumPy arrays\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    if x.shape[0] != y.shape[0]:\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
    "\n",
    "    # Initializing the values of the variables\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "\n",
    "    # Setting up and checking the learning rate\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    if np.any(learn_rate <= 0):\n",
    "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the maximal number of iterations\n",
    "    n_iter = int(n_iter)\n",
    "    if n_iter <= 0:\n",
    "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the tolerance\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    if np.any(tolerance <= 0):\n",
    "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
    "\n",
    "    # Performing the gradient descent loop\n",
    "    for _ in range(n_iter):\n",
    "        # Recalculating the difference\n",
    "        diff = -learn_rate * np.array(gradient(x, y, vector), dtype_)\n",
    "\n",
    "        # Checking if the absolute difference is small enough\n",
    "        if np.all(np.abs(diff) <= tolerance):\n",
    "            break\n",
    "\n",
    "        # Updating the values of the variables\n",
    "        vector += diff\n",
    "\n",
    "    return vector if vector.shape else vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ae205625",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(\n",
    "    gradient, x, y, start, learn_rate=0.1, batch_size=1, n_iter=50,\n",
    "    tolerance=1e-06, dtype=\"float64\", random_state=None\n",
    "):\n",
    "    # Checking if the gradient is callable\n",
    "    if not callable(gradient):\n",
    "        raise TypeError(\"'gradient' must be callable\")\n",
    "\n",
    "    # Setting up the data type for NumPy arrays\n",
    "    dtype_ = np.dtype(dtype)\n",
    "\n",
    "    # Converting x and y to NumPy arrays\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    n_obs = x.shape[0]\n",
    "    if n_obs != y.shape[0]:\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
    "    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n",
    "\n",
    "    # Initializing the random number generator\n",
    "    seed = None if random_state is None else int(random_state)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    # Initializing the values of the variables\n",
    "    vector = np.array(start, dtype=dtype_)\n",
    "\n",
    "    # Setting up and checking the learning rate\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    if np.any(learn_rate <= 0):\n",
    "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the size of minibatches\n",
    "    batch_size = int(batch_size)\n",
    "    if not 0 < batch_size <= n_obs:\n",
    "        raise ValueError(\n",
    "            \"'batch_size' must be greater than zero and less than \"\n",
    "            \"or equal to the number of observations\"\n",
    "        )\n",
    "\n",
    "    # Setting up and checking the maximal number of iterations\n",
    "    n_iter = int(n_iter)\n",
    "    if n_iter <= 0:\n",
    "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the tolerance\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    if np.any(tolerance <= 0):\n",
    "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
    "\n",
    "    # Performing the gradient descent loop\n",
    "    for _ in range(n_iter):\n",
    "        # Shuffle x and y\n",
    "        rng.shuffle(xy)\n",
    "\n",
    "        # Performing minibatch moves\n",
    "        for start in range(0, n_obs, batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n",
    "\n",
    "            # Recalculating the difference\n",
    "            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n",
    "            diff = -learn_rate * grad\n",
    "\n",
    "            # Checking if the absolute difference is small enough\n",
    "            if np.all(np.abs(diff) <= tolerance):\n",
    "                break\n",
    "\n",
    "            # Updating the values of the variables\n",
    "            vector += diff\n",
    "\n",
    "    return vector if vector.shape else vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f1ab13e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.63093736, 0.53982921])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd(ssr_gradient, x, y, start=[0.5, 0.5], learn_rate=0.0008,batch_size=3, n_iter=100_000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7f6f1f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgd(\n",
    "    gradient, x, y, n_vars=None, start=None, learn_rate=0.1,\n",
    "    decay_rate=0.0, batch_size=1, n_iter=50, tolerance=1e-06,\n",
    "    dtype=\"float64\", random_state=None\n",
    "):\n",
    "    # Checking if the gradient is callable\n",
    "    if not callable(gradient):\n",
    "        raise TypeError(\"'gradient' must be callable\")\n",
    "\n",
    "    # Setting up the data type for NumPy arrays\n",
    "    dtype_ = np.dtype(dtype)\n",
    "\n",
    "    # Converting x and y to NumPy arrays\n",
    "    x, y = np.array(x, dtype=dtype_), np.array(y, dtype=dtype_)\n",
    "    n_obs = x.shape[0]\n",
    "    if n_obs != y.shape[0]:\n",
    "        raise ValueError(\"'x' and 'y' lengths do not match\")\n",
    "    xy = np.c_[x.reshape(n_obs, -1), y.reshape(n_obs, 1)]\n",
    "\n",
    "    # Initializing the random number generator\n",
    "    seed = None if random_state is None else int(random_state)\n",
    "    rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    # Initializing the values of the variables\n",
    "    vector = (\n",
    "        rng.normal(size=int(n_vars)).astype(dtype_)\n",
    "        if start is None else\n",
    "        np.array(start, dtype=dtype_)\n",
    "    )\n",
    "\n",
    "    # Setting up and checking the learning rate\n",
    "    learn_rate = np.array(learn_rate, dtype=dtype_)\n",
    "    if np.any(learn_rate <= 0):\n",
    "        raise ValueError(\"'learn_rate' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the decay rate\n",
    "    decay_rate = np.array(decay_rate, dtype=dtype_)\n",
    "    if np.any(decay_rate < 0) or np.any(decay_rate > 1):\n",
    "        raise ValueError(\"'decay_rate' must be between zero and one\")\n",
    "\n",
    "    # Setting up and checking the size of minibatches\n",
    "    batch_size = int(batch_size)\n",
    "    if not 0 < batch_size <= n_obs:\n",
    "        raise ValueError(\n",
    "            \"'batch_size' must be greater than zero and less than \"\n",
    "            \"or equal to the number of observations\"\n",
    "        )\n",
    "\n",
    "    # Setting up and checking the maximal number of iterations\n",
    "    n_iter = int(n_iter)\n",
    "    if n_iter <= 0:\n",
    "        raise ValueError(\"'n_iter' must be greater than zero\")\n",
    "\n",
    "    # Setting up and checking the tolerance\n",
    "    tolerance = np.array(tolerance, dtype=dtype_)\n",
    "    if np.any(tolerance <= 0):\n",
    "        raise ValueError(\"'tolerance' must be greater than zero\")\n",
    "\n",
    "    # Setting the difference to zero for the first iteration\n",
    "    diff = 0\n",
    "\n",
    "    # Performing the gradient descent loop\n",
    "    for _ in range(n_iter):\n",
    "        # Shuffle x and y\n",
    "        rng.shuffle(xy)\n",
    "\n",
    "        # Performing minibatch moves\n",
    "        for start in range(0, n_obs, batch_size):\n",
    "            stop = start + batch_size\n",
    "            x_batch, y_batch = xy[start:stop, :-1], xy[start:stop, -1:]\n",
    "\n",
    "            # Recalculating the difference\n",
    "            grad = np.array(gradient(x_batch, y_batch, vector), dtype_)\n",
    "            diff = decay_rate * diff - learn_rate * grad\n",
    "\n",
    "            # Checking if the absolute difference is small enough\n",
    "            if np.all(np.abs(diff) <= tolerance):\n",
    "                break\n",
    "\n",
    "            # Updating the values of the variables\n",
    "            vector += diff\n",
    "\n",
    "    return vector if vector.shape else vector.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "23e19b65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5.63014443, 0.53901017])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgd(ssr_gradient, x, y, n_vars=2, learn_rate=0.0001,decay_rate=0.8, batch_size=3, n_iter=100_000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6da2d16f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/54/9zy0h1lx30352ghjszc5g2h80000gn/T/ipykernel_3444/1112609469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Create needed objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0msgd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSGD\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.9\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mvar\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Perform optimization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "# Create needed objects\n",
    "sgd = tf.keras.optimizers.SGD(learning_rate=0.1, momentum=0.9)\n",
    "var = tf.Variable(2.5)\n",
    "cost = lambda: 2 + var ** 2\n",
    "# Perform optimization\n",
    "for _ in range(100):\n",
    "    sgd.minimize(cost, var_list=[var])\n",
    "# Extract results\n",
    "var.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb9fb641",
   "metadata": {},
   "outputs": [],
   "source": [
    "cost().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
